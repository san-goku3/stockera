{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 15s 1s/step - loss: 816.0311 - mae: 21.3022 - val_loss: 1200.8123 - val_mae: 23.0709\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 809.8721 - mae: 21.2224 - val_loss: 1193.0605 - val_mae: 23.0294\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 801.8362 - mae: 21.1157 - val_loss: 1183.8148 - val_mae: 22.9988\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 793.4057 - mae: 21.0060 - val_loss: 1171.7119 - val_mae: 22.9602\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 780.7628 - mae: 20.8400 - val_loss: 1154.4950 - val_mae: 22.9086\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 767.8802 - mae: 20.6366 - val_loss: 1131.7623 - val_mae: 22.8507\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 744.8575 - mae: 20.3596 - val_loss: 1105.5614 - val_mae: 22.8144\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 721.5914 - mae: 19.9873 - val_loss: 1082.7979 - val_mae: 22.8486\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 697.4813 - mae: 19.6946 - val_loss: 1067.5171 - val_mae: 22.9257\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 685.8802 - mae: 19.6422 - val_loss: 1055.5807 - val_mae: 22.9804\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 673.3058 - mae: 19.4859 - val_loss: 1044.4602 - val_mae: 23.0089\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 660.6099 - mae: 19.3438 - val_loss: 1034.2367 - val_mae: 23.0604\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 657.8333 - mae: 19.3473 - val_loss: 1025.3818 - val_mae: 23.1252\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 648.7366 - mae: 19.2762 - val_loss: 1018.0046 - val_mae: 23.1812\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 639.6396 - mae: 19.1717 - val_loss: 1012.1797 - val_mae: 23.2263\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 626.2612 - mae: 18.9329 - val_loss: 1007.7305 - val_mae: 23.2607\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 621.2046 - mae: 18.8396 - val_loss: 1003.7995 - val_mae: 23.2908\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 617.1121 - mae: 18.7185 - val_loss: 1000.4632 - val_mae: 23.3161\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 616.1820 - mae: 18.8586 - val_loss: 997.7005 - val_mae: 23.3369\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 618.5233 - mae: 18.9528 - val_loss: 994.9166 - val_mae: 23.3584\n",
      "Model and scaler saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Load Dataset\n",
    "dataset_path = \"../data/IPO_dataset.csv\"  # Adjust path as needed\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Define Features and Target\n",
    "features = ['issue_price', 'issue_size', 'hni_subscription', 'nii_subscription',\n",
    "            'rii_subscription', 'revenue_2', 'revenue_1', 'eps_2', 'eps_1']  # Use only these 9 features\n",
    "target = 'listing_gain'\n",
    "\n",
    "# Drop Missing Values\n",
    "data = data.dropna(subset=features + [target])\n",
    "\n",
    "# Scale Only Features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(data[features])  # Scale features only\n",
    "y = data[target].values  # Keep target unscaled\n",
    "\n",
    "# Combine Scaled Features and Target for Sequence Creation\n",
    "data_scaled = np.hstack((X_scaled, y.reshape(-1, 1)))\n",
    "\n",
    "# Create Sequences for LSTM\n",
    "def create_sequences(data, time_steps=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:i + time_steps, :-1])  # Features\n",
    "        y.append(data[i + time_steps, -1])    # Target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data_scaled, time_steps=10)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)  # Predict Listing Gain\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save Model and Scaler\n",
    "model.save(\"../models/best_lstm_model.h5\")\n",
    "with open(\"../models/scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Model and scaler saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
